---
title: "Advanced Data Science-Final Project"
output:
  html_document:
    df_print: paged
---

The 80/20 rule has proven true for many businesses–only a small percentage of customers produce most of the revenue. As such, marketing teams are challenged to make appropriate investments in promotional strategies.

GStore
RStudio, the developer of free and open tools for R and enterprise-ready products for teams to scale and share work, has partnered with Google Cloud and Kaggle to demonstrate the business impact that thorough data analysis can have.

In this competition, you’re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data

# Exploratory Data Analysis(EDA)
First we read the data into R
```{r}
library(tidyverse)
dat <- read_csv("/Users/chenhuan/Downloads/Data-3/train_US_1year_nojson.csv")
```
Then, take a glimpse at the data
```{r}
## Dimension of the dat
dim(dat)
## Take a glimpse at the dat
glimpse(dat)
## Summary of the dat
summary(dat)
## The head part of the dat
head(dat)

```

```{r}
library(ggplot2)
library(lubridate)
## Density of the transactionRevenue
dat %>% 
  select(fullVisitorId, totalTransactionRevenue) %>%
  group_by(fullVisitorId) %>% 
  summarise(total.revenue = sum(log(na.omit(totalTransactionRevenue)))) %>% 
  ggplot(aes(x = total.revenue) ) + 
  geom_density()

## Total number of visotor
visitor.num = length(unique(dat$fullVisitorId))
print(paste0("The total number of different visitors is ", visitor.num))

## The distribution of how browsers are used
dat %>% 
  group_by(browser) %>%
  summarise(n = n()) %>%
  top_n(10) %>%
  ggplot(aes(x = browser, y = n / sum(n))) +
  geom_bar(stat="identity") + 
  ggtitle("Distribution of the top 10 mostly used browsers") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylab("Percentage") + 
  xlab("Browser Type")

## The distribution of the device
dat %>% 
  group_by(deviceCategory) %>%
  summarise(n = n()) %>%
  top_n(10) %>%
  ggplot(aes(x = deviceCategory, y = n / sum(n))) +
  geom_bar(stat="identity") + 
  ggtitle("Distribution of the devices") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylab("Percentage") + 
  xlab("Browser Type")

## The distribution of the OS
dat %>% 
  group_by(operatingSystem) %>%
  summarise(n = n()) %>%
  top_n(10) %>%
  ggplot(aes(x = operatingSystem, y = n / sum(n))) +
  geom_bar(stat="identity") + 
  ggtitle("Distribution of the operating system") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylab("Percentage") + 
  xlab("Operating System")

## The trend of the revenue with respect to the time 
dat %>% 
  mutate(date = ymd(date)) %>%
  group_by(date) %>%
  summarise(total.revenue = sum(na.omit(totalTransactionRevenue))) %>%
  ggplot(aes(x = date, y = total.revenue)) + 
  geom_line(smooth = "line") + 
  ggtitle("Time Series of totalTransactionRevenue") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylab("totalTransactionRevenue") + 
  xlab("Data")

## Mobile or Unmobile
dat %>% 
  group_by(isMobile) %>%
  summarise(n = n()) %>%
  ggplot(aes(x = isMobile, y = n / sum(n))) +
  geom_bar(stat="identity") + 
  ggtitle("Mobile or Unmobile") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  ylab("Percentage") + 
  xlab("IsMobile")




```

Study the geographical information
```{r}
library(usmap)
## The revenue corresponds to the different states in USA
map.revenue <- dat %>% 
  select(region) %>%
  group_by(region) %>%
  summarise(n = log(n())) %>% 
  rename(full = region)
  
state.google <- statepop %>% 
  select(fips, abbr, full) %>%
  left_join(map.revenue, by = "full")

state.google$n[is.na(state.google$n)] = 0
  
## Plot the map
plot_usmap(data = state.google, values = "n", lines = "red") + 
scale_fill_continuous(
    low = "white", high = "red", name = "log(totalTransactionRevenue)", label = scales::comma
  ) + theme(legend.position = "right")

```


```{r}
## take a glimpse at the data
library(caret)
library(missForest)

## Take a quick glimpse at the data
glimpse(dat)

## The columns which will be discarded in the end
col.miss = c()

## Set NA TransactionRevenue into 0
dat$transactionRevenue[is.na(dat$transactionRevenue)] = 0
dat$newVisits[is.na(dat$newVisits)] = 0

##
for(i in 1 : ncol(dat)){
  miss.temp = sum(is.na(dat[,i])) / nrow(dat)
  if(miss.temp <= 0.7){
    col.miss = c(col.miss, i)
  }
}

dat.miss = dat[, col.miss]
index.variable = c("channelGrouping", "browser", "operatingSystem", 
          "isMobile", "deviceCategory", 
          "hits1", "pageviews", "timeOnSite", "sessionQualityDim",
          "newVisits", "transactionRevenue")
dat.miss <- dat.miss[, index.variable]

## Add one new "other" category for the browser category
name.browser.other <- sort(table(dat.miss$browser))[sort(table(dat.miss$browser)) <= 10] %>% names
dat.miss$browser[dat.miss$browser %in% name.browser.other] <- "Others"

## Add one new "other" category for the Operating System category
name.os.other <- sort(table(dat.miss$browser))[sort(table(dat.miss$operatingSystem)) <= 10] %>% names
dat.miss$operatingSystem[dat.miss$operatingSystem %in% name.os.other] <- "Others"

## Construct the training and testing dataset
train.index <- sample(1 : nrow(dat.miss), 0.7 * nrow(dat.miss), replace = FALSE)
dat.train <- dat.miss[train.index, ]
dat.test <- dat.miss[-train.index, ]

## The Cross-Validation procedure
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"

fit_LinearModel <- train(transactionRevenue~., data=dat.train, method="lm",
                metric=metric, trControl=control)



```

